{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb213275",
   "metadata": {},
   "source": [
    "# APIs para GPTs e outros LLMs no Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6776f18",
   "metadata": {},
   "source": [
    "## Por quê usar LLMs no Python:\n",
    "1) Automatização\n",
    "2) Controle\n",
    "3) Escala \n",
    "\n",
    "## O que esse treinamento deve proporcionar\n",
    "1) Configuração do ambiente: como criar e onde salvar a chave da API, como estabelecer limites de gastos\n",
    "2) Primeiros passos: fazendo uma requisição básica\n",
    "3) Trabalhando em escala: como utilizar batchs (síncrono e assíncrono)\n",
    "4) Ganhando complexidade: use case Reclame Aqui "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece501b",
   "metadata": {},
   "source": [
    "Observações: utilizar YAML \n",
    "agents/\n",
    "    - mapeador de tendências.yaml\n",
    "    - comparador_entre_trend_e_macrotrend.yaml\n",
    "    - ...\n",
    "\n",
    "yaml:\n",
    "    - modelo de API (ex: gpt4o)\n",
    "    - temperatura\n",
    "    - outros parâmetros\n",
    "    - sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae1005",
   "metadata": {},
   "source": [
    "## 1) Configurando o ambiente \n",
    "\n",
    "Application Programming Interface (APIs) são como pontes padronizadas para que dois sistemas conversem com segurança e rapidez. Na prática, serve para que possamos extrair funcionalidades de aplicações sem que seja necessário entendermos o que tem por trás da aplicação, apenas como nos conectar. APIs envolvem algumas regras, como autenticação, limites de pedidos e horário de funcionamneto.\n",
    "\n",
    "No caso de LLMs, a API serve para utilizarmos modelos sem que precisemos de todo a aplicação web. No geral, o processo é parecido para quase todos os provedores (OpenAI, Google, Anthropic). Diferente da utilização tradicional em que se paga uma mensalidade, na utilização de APIs se paga por tokens utilizados (input/output). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3a5d4",
   "metadata": {},
   "source": [
    "### Criando uma chave\n",
    "\n",
    "O processo de criação é bem simples. Para a OpenAI, LLM que estaremos utilizando principalmente nesse treinamento, você pode criar sua própria chave aqui https://platform.openai.com/api-keys. Na maioria dos casos, você só consegue ler a chave completa quando cria, e após isso ela fica em grande parte oculta por segurança.\n",
    "\n",
    "A chave terá um formato similar a esse: \"sk-proj-XlTrIjLDJ....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12112fb6",
   "metadata": {},
   "source": [
    "### Onde armazenar sua chave\n",
    "É importante que sua chave fique armazenada em um local seguro. Para isso, normalmente utilizamos um arquivo \".env\". Ele é onde você armazenam variáveis que dependem da máquina ou que não devem ser salvas em seu .git ou em locais públicos. O .env não é 100% seguro mas é bom para variáveis específicas da máquina ou usuário. \n",
    "\n",
    "No caso de utilizarmos .git em algum projeto, é recomendado deixar o .env dentro do .gitignore para evitarmos que essas variáveis sejam enviadas ao repositório.\n",
    "\n",
    "A Mirow possui chaves para utilização geral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd8a1c",
   "metadata": {},
   "source": [
    "## 2) Realizando requisições \n",
    "Vamos fazer uma requisição básica a OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7676dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Vamos considerar um exemplo prático de uso de uma API em um contexto de um modelo de linguagem grande (LLM).\n",
      "\n",
      "### Exemplo: Usando a API do OpenAI para gerar texto\n",
      "\n",
      "Suponha que você deseja criar um aplicativo que gera resumos de textos longos usando um modelo de linguagem como o GPT da OpenAI. Aqui está como você poderia fazer isso usando a API do OpenAI:\n",
      "\n",
      "1. **Obtenção da chave da API**: Primeiro, você precisaria se inscrever no serviço da OpenAI e obter uma chave da API, que permitirá que você faça requisições ao modelo.\n",
      "\n",
      "2. **Configuração do ambiente**: Você precisaria de um ambiente Python com a biblioteca `requests` instalada. Você pode instalá-la usando o pip:\n",
      "\n",
      "   ```bash\n",
      "   pip install requests\n",
      "   ```\n",
      "\n",
      "3. **Fazendo uma requisição à API**: Aqui está um exemplo de código que realiza uma requisição para gerar um resumo:\n",
      "\n",
      "   ```python\n",
      "   import requests\n",
      "\n",
      "   # Defina sua chave da API\n",
      "   api_key = 'sua_chave_da_api_aqui'\n",
      "\n",
      "   # O texto que você deseja resumir\n",
      "   texto_para_resumir = \"\"\"Aqui está um texto longo que você deseja resumir...\n",
      "   \"\"\"\n",
      "\n",
      "   # Endpoint da API do OpenAI\n",
      "   url = \"https://api.openai.com/v1/chat/completions\"\n",
      "\n",
      "   # Configurando o cabeçalho da requisição\n",
      "   headers = {\n",
      "       \"Authorization\": f\"Bearer {api_key}\",\n",
      "       \"Content-Type\": \"application/json\"\n",
      "   }\n",
      "\n",
      "   # Configurando o corpo da requisição\n",
      "   data = {\n",
      "       \"model\": \"gpt-3.5-turbo\",\n",
      "       \"messages\": [{\"role\": \"user\", \"content\": f\"Resuma o seguinte texto: {texto_para_resumir}\"}],\n",
      "       \"max_tokens\": 100  # Limita o tamanho do resumo\n",
      "   }\n",
      "\n",
      "   # Fazendo a requisição\n",
      "   response = requests.post(url, headers=headers, json=data)\n",
      "\n",
      "   # Verificando a resposta\n",
      "   if response.status_code == 200:\n",
      "       resumo = response.json()['choices'][0]['message']['content']\n",
      "       print(\"Resumo:\", resumo)\n",
      "   else:\n",
      "       print(\"Erro:\", response.status_code, response.text)\n",
      "   ```\n",
      "\n",
      "### Por que isso é importante?\n",
      "\n",
      "1. **Acesso a Modelos Poderosos**: Usar uma API permite que você acesse modelos de linguagem avançados sem precisar treinar um do zero, economizando tempo e recursos.\n",
      "\n",
      "2. **Facilidade de Integração**: APIs permitem que você integre funcionalidades avançadas em seus aplicativos de forma simples e rápida, utilizando apenas chamadas de rede.\n",
      "\n",
      "3. **Atualizações e Manutenção**: As APIs são mantidas pelos provedores (como a OpenAI), o que significa que você se beneficia de melhorias e atualizações sem precisar modificar seu código.\n",
      "\n",
      "4. **Escalabilidade**: Ao usar uma API, você pode escalar seu aplicativo conforme necessário, já que o provedor se encarrega da infraestrutura.\n",
      "\n",
      "Esse exemplo ilustra como as APIs são uma ferramenta poderosa para trabalhar com LLMs, permitindo que desenvolvedores criem aplicações complexas de maneira eficiente.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa o cliente\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Requisição\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",  # Instruções de alto nível para o modelo (tom, formato, regras)\n",
    "            \"content\": \"Você é um especialista em Python e análise de dados. Responda de forma clara e didática.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",  # Pergunta ou comando do usuário\n",
    "            \"content\": \"Explique o que são APIs e por que são importantes para trabalhar com LLMs.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",  # Resposta já geradas do assistente (modelo)\n",
    "            \"content\": \"APIs são interfaces que permitem comunicação entre sistemas diferentes de forma padronizada.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",  # Nova pergunta ou comando do usuário\n",
    "            \"content\": \"Agora me dê um exemplo prático de uso.\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# Exibe a resposta\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda6f54",
   "metadata": {},
   "source": [
    "**Principais parâmetros:**\n",
    "- `model`: modelo a ser utilizado (ex: gpt-4o, gpt-4o-mini, gpt-3.5-turbo)\n",
    "- `messages`: lista de mensagens com roles (system, user, assistant)\n",
    "- `temperature`: criatividade da resposta (0 a 2), dependendo da aplicação\n",
    "- `max_tokens`: limite de tokens na resposta\n",
    "- `response_format`: força o modelo a retornar dados em formato estruturado específico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50b7cd",
   "metadata": {},
   "source": [
    "Além de OpenAI, podemos utilizar outras LLMs como Claude ou Gemini. Também é possível usar LiteLLM, que possibilita variedade de LLMs em um único ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude (Anthropic)\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"...\"}],\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Gemini (Google)\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "response = model.generate_content(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15d730e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LengthFinishReasonError",
     "evalue": "Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=800, prompt_tokens=179, total_tokens=979, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLengthFinishReasonError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Requisição para pensarmos em tendências de um mercado\u001b[39;00m\n\u001b[32m     21\u001b[39m response_temperature1 = client.chat.completions.create(\n\u001b[32m     22\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     messages=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     max_tokens=\u001b[32m800\u001b[39m,\n\u001b[32m     43\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m response_temperature2 = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an automotive market analyst. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mList the 10 main automotive trends in Brazil following the required JSON schema.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTendenciasResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:183\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    178\u001b[39m         response_format=response_format,\n\u001b[32m    179\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    180\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1052\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1141\u001b[39m, in \u001b[36mSyncAPIClient._process_response\u001b[39m\u001b[34m(self, cast_to, options, response, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(response.request.headers.get(RAW_RESPONSE_HEADER)):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, api_response)\n\u001b[32m-> \u001b[39m\u001b[32m1141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_response.py:325\u001b[39m, in \u001b[36mAPIResponse.parse\u001b[39m\u001b[34m(self, to)\u001b[39m\n\u001b[32m    323\u001b[39m parsed = \u001b[38;5;28mself\u001b[39m._parse(to=to)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_given(\u001b[38;5;28mself\u001b[39m._options.post_parser):\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     parsed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parsed, BaseModel):\n\u001b[32m    328\u001b[39m     add_request_id(parsed, \u001b[38;5;28mself\u001b[39m.request_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:177\u001b[39m, in \u001b[36mCompletions.parse.<locals>.parser\u001b[39m\u001b[34m(raw_completion)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchat_completion_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Joao\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py:100\u001b[39m, in \u001b[36mparse_chat_completion\u001b[39m\u001b[34m(response_format, input_tools, chat_completion)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m chat_completion.choices:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m choice.finish_reason == \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LengthFinishReasonError(completion=chat_completion)\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m choice.finish_reason == \u001b[33m\"\u001b[39m\u001b[33mcontent_filter\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterFinishReasonError()\n",
      "\u001b[31mLengthFinishReasonError\u001b[39m: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=800, prompt_tokens=179, total_tokens=979, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "# Exemplo de uso de response_format com Structured Outputs\n",
    "\n",
    "\n",
    "# Definir o schema com Pydantic\n",
    "class Tendencia(BaseModel):\n",
    "    nome: str\n",
    "    descricao: str\n",
    "    impacto: Literal[\"alto\", \"medio\", \"baixo\"]\n",
    "    prazo: Literal[\"curto\", \"medio\", \"longo\"]\n",
    "\n",
    "\n",
    "class TendenciasResponse(BaseModel):\n",
    "    tendencias: list[Tendencia]\n",
    "\n",
    "\n",
    "# Requisição para pensarmos em tendências de um mercado\n",
    "response_temperature1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an automotive market analyst. \"\n",
    "                \"Return ONLY valid JSON with the schema: \"\n",
    "                '{\"tendencias\": [{\"nome\": str, \"descricao\": str, '\n",
    "                '\"impacto\": \"alto|medio|baixo\", \"prazo\": \"curto|medio|longo\"}]} '\n",
    "                \"No extra text, markdown, or code fences.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"List the 10 main automotive trends in Brazil following the required JSON schema.\"\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=800,\n",
    ")\n",
    "\n",
    "response_temperature2 = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\"You are an automotive market analyst. \"),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"List the 10 main automotive trends in Brazil following the required JSON schema.\"\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    response_format=TendenciasResponse,\n",
    "    temperature=1.5,\n",
    "    max_tokens=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa299bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao decodificar JSON de temperature2: Expecting ',' delimiter: line 12 column 259 (char 681)\n",
      "Resposta recebida (primeiros 500 caracteres):\n",
      "{\n",
      "  \"tendencias\": [\n",
      "    {\n",
      "      \"nome\": \"Veículos Elétricos\",\n",
      "      \"descricao\": \"A expansão da linha de veículos elétricos comerciais e particulares em resposta às crescentes preocupações ambientais.\",\n",
      "      \"impacto\": \"alto\",\n",
      "      \"prazo\": \"medio\"\n",
      "    },\n",
      "    {\n",
      "      \"nome\": \"Conectividade\",\n",
      "      \"descricao\": \"Interação e integração de veículos com estratégia em casa, por meio de aplicativos e sistemas integrados.\",\n",
      "      \"impacto\": \"altamente amplia automaticamente as futuras infraestruturas\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_temperature1 = response_temperature1.choices[0].message.content\n",
    "data_temperature2 = response_temperature2.choices[0].message.content\n",
    "\n",
    "# Tentar carregar JSON com tratamento de erro\n",
    "try:\n",
    "    payload1 = json.loads(data_temperature1)\n",
    "    df_temperature1 = pd.json_normalize(payload1[\"tendencias\"])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Erro ao decodificar JSON de temperature1: {e}\")\n",
    "    df_temperature1 = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    payload2 = json.loads(data_temperature2)\n",
    "    df_temperature2 = pd.json_normalize(payload2[\"tendencias\"])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Erro ao decodificar JSON de temperature2: {e}\")\n",
    "    print(\"Resposta recebida (primeiros 500 caracteres):\")\n",
    "    print(data_temperature2[:500])\n",
    "    df_temperature2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a71fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "descricao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "impacto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prazo",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "16cdc645-1e77-49e6-8b4a-d5284ac2ef82",
       "rows": [
        [
         "0",
         "Veículos Elétricos",
         "Aumento na adoção de veículos elétricos devido a incentivos governamentais e preocupação ambiental.",
         "alto",
         "medio"
        ],
        [
         "1",
         "Carros Conectados",
         "Integração de tecnologia de conectividade nos veículos, permitindo comunicação entre carros e infraestrutura.",
         "alto",
         "medio"
        ],
        [
         "2",
         "Mobilidade Urbana",
         "Crescimento de soluções de mobilidade urbana, como caronas e serviços de compartilhamento de veículos.",
         "medio",
         "curto"
        ],
        [
         "3",
         "Autonomia Veicular",
         "Desenvolvimento de tecnologias para veículos autônomos, com testes e regulamentações em andamento.",
         "alto",
         "longo"
        ],
        [
         "4",
         "Sustentabilidade",
         "Foco em práticas sustentáveis na produção e operação de veículos, incluindo reciclagem e uso de materiais ecológicos.",
         "medio",
         "medio"
        ],
        [
         "5",
         "Carros Híbridos",
         "Aumento na venda de veículos híbridos como uma alternativa entre carros a combustão e elétricos.",
         "medio",
         "curto"
        ],
        [
         "6",
         "Tecnologia de Assistência ao Motorista",
         "Implementação de sistemas avançados de assistência ao motorista (ADAS) para aumentar a segurança.",
         "alto",
         "medio"
        ],
        [
         "7",
         "Mudanças Regulatórias",
         "Novas regulamentações ambientais e de segurança que afetam a produção e venda de veículos.",
         "alto",
         "curto"
        ],
        [
         "8",
         "Digitalização da Experiência do Cliente",
         "Adoção de plataformas digitais para vendas, serviços e atendimento ao cliente no setor automotivo.",
         "medio",
         "curto"
        ],
        [
         "9",
         "Aumento da Concorrência",
         "Entrada de novas montadoras e startups no mercado, aumentando a competição e inovação.",
         "medio",
         "medio"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>descricao</th>\n",
       "      <th>impacto</th>\n",
       "      <th>prazo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veículos Elétricos</td>\n",
       "      <td>Aumento na adoção de veículos elétricos devido...</td>\n",
       "      <td>alto</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carros Conectados</td>\n",
       "      <td>Integração de tecnologia de conectividade nos ...</td>\n",
       "      <td>alto</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mobilidade Urbana</td>\n",
       "      <td>Crescimento de soluções de mobilidade urbana, ...</td>\n",
       "      <td>medio</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autonomia Veicular</td>\n",
       "      <td>Desenvolvimento de tecnologias para veículos a...</td>\n",
       "      <td>alto</td>\n",
       "      <td>longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sustentabilidade</td>\n",
       "      <td>Foco em práticas sustentáveis na produção e op...</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Carros Híbridos</td>\n",
       "      <td>Aumento na venda de veículos híbridos como uma...</td>\n",
       "      <td>medio</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tecnologia de Assistência ao Motorista</td>\n",
       "      <td>Implementação de sistemas avançados de assistê...</td>\n",
       "      <td>alto</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mudanças Regulatórias</td>\n",
       "      <td>Novas regulamentações ambientais e de seguranç...</td>\n",
       "      <td>alto</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Digitalização da Experiência do Cliente</td>\n",
       "      <td>Adoção de plataformas digitais para vendas, se...</td>\n",
       "      <td>medio</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aumento da Concorrência</td>\n",
       "      <td>Entrada de novas montadoras e startups no merc...</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      nome  \\\n",
       "0                       Veículos Elétricos   \n",
       "1                        Carros Conectados   \n",
       "2                        Mobilidade Urbana   \n",
       "3                       Autonomia Veicular   \n",
       "4                         Sustentabilidade   \n",
       "5                          Carros Híbridos   \n",
       "6   Tecnologia de Assistência ao Motorista   \n",
       "7                    Mudanças Regulatórias   \n",
       "8  Digitalização da Experiência do Cliente   \n",
       "9                  Aumento da Concorrência   \n",
       "\n",
       "                                           descricao impacto  prazo  \n",
       "0  Aumento na adoção de veículos elétricos devido...    alto  medio  \n",
       "1  Integração de tecnologia de conectividade nos ...    alto  medio  \n",
       "2  Crescimento de soluções de mobilidade urbana, ...   medio  curto  \n",
       "3  Desenvolvimento de tecnologias para veículos a...    alto  longo  \n",
       "4  Foco em práticas sustentáveis na produção e op...   medio  medio  \n",
       "5  Aumento na venda de veículos híbridos como uma...   medio  curto  \n",
       "6  Implementação de sistemas avançados de assistê...    alto  medio  \n",
       "7  Novas regulamentações ambientais e de seguranç...    alto  curto  \n",
       "8  Adoção de plataformas digitais para vendas, se...   medio  curto  \n",
       "9  Entrada de novas montadoras e startups no merc...   medio  medio  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1cbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "descricao",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "impacto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prazo",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4d63a15d-da6b-4a60-9d7c-17c91498fcfe",
       "rows": [
        [
         "0",
         "Eletrificação dos Veículos",
         "Crescimento no mercado de veículos elétricos e híbridos, impulsionado por incentivos governamentais e pela demanda por viagens sustentáveis.",
         "alto",
         "medio"
        ],
        [
         "1",
         "Digitalização e Conectividade",
         "Integração de tecnologias de conectividade, incluindo sistemas de infotainment e aplicativos para controles de carro via smartphone.",
         "alto",
         "curto"
        ],
        [
         "2",
         "Veículos Autônomos",
         "Pesquisas para desenvolvimento de veículos autônomos têm avançado, apesar de regulatórias ainda restritivas no Brasil.",
         "medio",
         "longo"
        ],
        [
         "3",
         "Foco em Sustentabilidade",
         "Marcas estão adotando práticas mais ecológicas na produção de veículos e utilização de matérias-primas alternativas.",
         "alto",
         "longo"
        ],
        [
         "4",
         "Recuperação e Crescimento Pós-Pandemia",
         "O mercado automotivo está mostrando sinais de recuperação planejando recuperação de estoques e atenção à demanda reprimida.",
         "alto",
         "curto"
        ],
        [
         "5",
         "Popularização dos SUVs",
         "A preferência por SUVs está crescendo entre os consumidores brasileiros em função de conforto e versatilidade.",
         "alto",
         "medio"
        ],
        [
         "6",
         "Uso de Tecnologia de Assistência ao Motorista",
         "Motoristas mostram maior interesse por localizadores, assistentes de estacionamento e monitoramento de segurança.",
         "medio",
         "curto"
        ],
        [
         "7",
         "Unificação das Plataformas CPFs",
         "Concentração no compartilhamento de melhores plataformas viabilizadas por grupos de fabricantes criando economia de escala.",
         "medio",
         "medio"
        ],
        [
         "8",
         "Aumento do E-commerce de Automóveis",
         "Veio devido à pandemia, um aumento no comercio de automóveis online. Vaticina-se a persistência dessa tendência.",
         "medio",
         "curto"
        ],
        [
         "9",
         "Mobilidade Servida como Serviço (MaaS)",
         "Modelos de compras de inicia-se a implementar para fundamental utilização estilos novos de limites sustentadoresurezza/client preto.",
         "baixo",
         "longo"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>descricao</th>\n",
       "      <th>impacto</th>\n",
       "      <th>prazo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eletrificação dos Veículos</td>\n",
       "      <td>Crescimento no mercado de veículos elétricos e...</td>\n",
       "      <td>alto</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digitalização e Conectividade</td>\n",
       "      <td>Integração de tecnologias de conectividade, in...</td>\n",
       "      <td>alto</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veículos Autônomos</td>\n",
       "      <td>Pesquisas para desenvolvimento de veículos aut...</td>\n",
       "      <td>medio</td>\n",
       "      <td>longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Foco em Sustentabilidade</td>\n",
       "      <td>Marcas estão adotando práticas mais ecológicas...</td>\n",
       "      <td>alto</td>\n",
       "      <td>longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recuperação e Crescimento Pós-Pandemia</td>\n",
       "      <td>O mercado automotivo está mostrando sinais de ...</td>\n",
       "      <td>alto</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Popularização dos SUVs</td>\n",
       "      <td>A preferência por SUVs está crescendo entre os...</td>\n",
       "      <td>alto</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uso de Tecnologia de Assistência ao Motorista</td>\n",
       "      <td>Motoristas mostram maior interesse por localiz...</td>\n",
       "      <td>medio</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unificação das Plataformas CPFs</td>\n",
       "      <td>Concentração no compartilhamento de melhores p...</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aumento do E-commerce de Automóveis</td>\n",
       "      <td>Veio devido à pandemia, um aumento no comercio...</td>\n",
       "      <td>medio</td>\n",
       "      <td>curto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mobilidade Servida como Serviço (MaaS)</td>\n",
       "      <td>Modelos de compras de inicia-se a implementar ...</td>\n",
       "      <td>baixo</td>\n",
       "      <td>longo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            nome  \\\n",
       "0                     Eletrificação dos Veículos   \n",
       "1                  Digitalização e Conectividade   \n",
       "2                             Veículos Autônomos   \n",
       "3                       Foco em Sustentabilidade   \n",
       "4         Recuperação e Crescimento Pós-Pandemia   \n",
       "5                         Popularização dos SUVs   \n",
       "6  Uso de Tecnologia de Assistência ao Motorista   \n",
       "7                Unificação das Plataformas CPFs   \n",
       "8            Aumento do E-commerce de Automóveis   \n",
       "9         Mobilidade Servida como Serviço (MaaS)   \n",
       "\n",
       "                                           descricao impacto  prazo  \n",
       "0  Crescimento no mercado de veículos elétricos e...    alto  medio  \n",
       "1  Integração de tecnologias de conectividade, in...    alto  curto  \n",
       "2  Pesquisas para desenvolvimento de veículos aut...   medio  longo  \n",
       "3  Marcas estão adotando práticas mais ecológicas...    alto  longo  \n",
       "4  O mercado automotivo está mostrando sinais de ...    alto  curto  \n",
       "5  A preferência por SUVs está crescendo entre os...    alto  medio  \n",
       "6  Motoristas mostram maior interesse por localiz...   medio  curto  \n",
       "7  Concentração no compartilhamento de melhores p...   medio  medio  \n",
       "8  Veio devido à pandemia, um aumento no comercio...   medio  curto  \n",
       "9  Modelos de compras de inicia-se a implementar ...   baixo  longo  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8136d31",
   "metadata": {},
   "source": [
    "## 3) Trabalhando em escala\n",
    "\n",
    "**Batches** permitem agrupar várias requisições em um único envio assíncrono. A API processa cada item separadamente, mas você ganha preço reduzido (tarifa de batch) e não precisa segurar a execução do seu código local enquanto a inferência acontece. O fluxo básico: gerar um arquivo NDJSON com todas as requisições, enviar esse arquivo para a OpenAI e disparar um job de batch. Depois, consultar o status até que os resultados estejam prontos e baixá-los.\n",
    "\n",
    "**Requisições assíncronas** (_async_) são úteis quando você quer disparar várias chamadas rápidas e continuar trabalhando enquanto espera o retorno. Em Python, usamos `asyncio` e o cliente assíncrono da OpenAI para mandar várias requisições em paralelo sem bloquear a thread principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904a81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de batch gerado em: C:\\Mirow\\Treinamento Python\\APIs\\Treinamento\\batch_requests.ndjson\n",
      "Batch criado: batch_6903a98366ac81909ba4f920e0855841\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "BATCH_COMPLETION_WINDOW = \"24h\"  # janela mínima exigida pela API no momento\n",
    "\n",
    "batch_requests = [\n",
    "    {\n",
    "        \"custom_id\": \"trend-macro-001\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are an automotive market analyst. Return ONLY valid JSON \"\n",
    "                        \"with keys: tendencias -> [{nome, descricao, impacto, prazo}]\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Liste 5 tendências automotivas no Brasil seguindo o schema solicitado.\",\n",
    "                },\n",
    "            ],\n",
    "            \"temperature\": 0.0,\n",
    "            \"max_tokens\": 400,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"custom_id\": \"trend-macro-002\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are an automotive market analyst. Return ONLY valid JSON \"\n",
    "                        \"with keys: tendencias -> [{nome, descricao, impacto, prazo}]\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Liste 5 tendências automotivas na Europa seguindo o schema solicitado.\",\n",
    "                },\n",
    "            ],\n",
    "            \"temperature\": 0.0,\n",
    "            \"max_tokens\": 400,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "batch_file = Path(\"batch_requests.ndjson\")\n",
    "batch_file.write_text(\n",
    "    \"\\n\".join(json.dumps(item) for item in batch_requests), encoding=\"utf-8\"\n",
    ")\n",
    "print(f\"Arquivo de batch gerado em: {batch_file.resolve()}\")\n",
    "\n",
    "uploaded = client.files.create(file=batch_file.open(\"rb\"), purpose=\"batch\")\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=uploaded.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=BATCH_COMPLETION_WINDOW,\n",
    ")\n",
    "print(\"Batch criado:\", batch_job.id)\n",
    "\n",
    "batch_job = client.batches.retrieve(batch_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfb974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status do batch batch_6903a98366ac81909ba4f920e0855841: completed\n",
      "\n",
      "✅ Batch completo! Baixando resultados...\n",
      "\n",
      "📦 Total de resultados: 2\n",
      "\n",
      "✓ Resultado 0 (trend-macro-001):\n",
      "  ```json\n",
      "{\n",
      "  \"tendencias\": [\n",
      "    {\n",
      "      \"nome\": \"Veículos Elétricos\",\n",
      "      \"descricao\": \"Aumento na...\n",
      "✓ Resultado 1 (trend-macro-002):\n",
      "  ```json\n",
      "{\n",
      "  \"tendencias\": [\n",
      "    {\n",
      "      \"nome\": \"Eletrificação de Veículos\",\n",
      "      \"descricao\": \"Aum...\n",
      "📦 Total de resultados: 2\n",
      "\n",
      "✓ Resultado 0 (trend-macro-001):\n",
      "  ```json\n",
      "{\n",
      "  \"tendencias\": [\n",
      "    {\n",
      "      \"nome\": \"Veículos Elétricos\",\n",
      "      \"descricao\": \"Aumento na...\n",
      "✓ Resultado 1 (trend-macro-002):\n",
      "  ```json\n",
      "{\n",
      "  \"tendencias\": [\n",
      "    {\n",
      "      \"nome\": \"Eletrificação de Veículos\",\n",
      "      \"descricao\": \"Aum...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa o cliente\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# batch_id = \"batch_6903a98366ac81909ba4f920e0855841\"\n",
    "batch_id = \"batch_6903a98366ac81909ba4f920e0855841\"\n",
    "\n",
    "batch_obj = client.batches.retrieve(batch_id)\n",
    "\n",
    "print(f\"Status do batch {batch_id}: {batch_obj.status}\")\n",
    "\n",
    "if batch_obj.status == \"completed\":\n",
    "    print(\"\\n✅ Batch completo! Baixando resultados...\\n\")\n",
    "    result_file_id = batch_obj.output_file_id\n",
    "    file_response = client.files.content(result_file_id)\n",
    "\n",
    "    # Processar linhas JSONL\n",
    "    results = []\n",
    "    for line in file_response.text.strip().split(\"\\n\"):\n",
    "        result = json.loads(line)\n",
    "        results.append(result)\n",
    "\n",
    "    print(f\"📦 Total de resultados: {len(results)}\\n\")\n",
    "\n",
    "    for idx, result in enumerate(results):\n",
    "        custom_id = result.get(\"custom_id\")\n",
    "        response_body = result.get(\"response\", {}).get(\"body\", {})\n",
    "\n",
    "        # Extrair conteúdo da resposta\n",
    "        message_content = (\n",
    "            response_body.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        )\n",
    "\n",
    "        print(f\"✓ Resultado {idx} ({custom_id}):\")\n",
    "        print(f\"  {message_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba3b9f",
   "metadata": {},
   "source": [
    "## 4) Use case: classificação de reclamações no Reclame Aqui\n",
    "\n",
    "### Project Structure\n",
    "\n",
    "```\n",
    "02. Classificador RA/\n",
    "├── main.py                    # Main orchestrator\n",
    "├── src/\n",
    "│   └── scraper.py                 # Phase 1: Data collection\n",
    "│   └──theme_discovery.py         # Phase 2: Theme discovery\n",
    "│   └──classifier.py              # Phase 4: Classification\n",
    "│   └──usage_tracker.py           # OpenAI API usage tracking\n",
    "│   └──view_usage.py              # View usage statistics\n",
    "│   └──config.py                  # Configuration\n",
    "├── requirements.txt           # Dependencies\n",
    "├── .env                       # Environment variables (create from .env.example)\n",
    "├── input/\n",
    "│   └── complaints_raw.json    # Scraped complaints (Phase 1 output)\n",
    "└── output/\n",
    "    ├── proposed_taxonomy.json        # Proposed categories (Phase 2 output)\n",
    "    ├── curated_taxonomy.json         # Final taxonomy (Phase 3 input)\n",
    "    ├── classification_results.json   # Classifications (Phase 4 output)\n",
    "    └── openai_usage.json             # API usage log (auto-generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188d86",
   "metadata": {},
   "source": [
    "### Execução direta da pipeline no notebook\n",
    "As células abaixo reutilizam os componentes do projeto para demonstrar cada fase sem sair do Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f5f85",
   "metadata": {},
   "source": [
    "#### Configuração: exibir estatísticas de uso da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a52b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de API habilitado. Estatísticas serão gravadas em: C:\\Mirow\\Treinamento Python\\APIs\\Treinamento\\02. Classificador RA\\output\\openai_usage.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"02. Classificador RA\").resolve()\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "import config\n",
    "\n",
    "# Nomes de arquivos e diretórios\n",
    "config.DATA_DIR = str(PROJECT_ROOT / \"data\")\n",
    "config.OUTPUT_DIR = str(PROJECT_ROOT / \"output\")\n",
    "config.API_USAGE_LOG_FILE = str(Path(config.OUTPUT_DIR) / \"openai_usage.json\")\n",
    "\n",
    "config.SHOW_API_USAGE = True\n",
    "config.SHOW_API_USAGE_DETAILS = False\n",
    "\n",
    "config.COMPLAINTS_FILE = str(Path(config.DATA_DIR) / \"complaints_raw.json\")\n",
    "config.PROPOSED_TAXONOMY_FILE = str(Path(config.OUTPUT_DIR) / \"proposed_taxonomy.json\")\n",
    "config.CURATED_TAXONOMY_FILE = str(Path(config.OUTPUT_DIR) / \"curated_taxonomy.json\")\n",
    "config.CLASSIFICATION_RESULTS_FILE = str(\n",
    "    Path(config.OUTPUT_DIR) / \"classification_results.json\"\n",
    ")\n",
    "\n",
    "Path(config.DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "complaints_path = Path(config.COMPLAINTS_FILE)\n",
    "fallback_path = PROJECT_ROOT / \"input\" / \"complaints_raw.json\"\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Uso de API habilitado. Estatísticas serão gravadas em:\", config.API_USAGE_LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5b762",
   "metadata": {},
   "source": [
    "#### 1. Scraping das reclamações (ou carregamento da base local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a656ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape: up to 20 pages\n",
      "Fetching page 1...\n",
      "Fetching page 1...\n",
      "✓ Extracted 10 complaints from page 1\n",
      "✓ Extracted 10 complaints from page 1\n",
      "Fetching page 2...\n",
      "Fetching page 2...\n",
      "✓ Extracted 10 complaints from page 2\n",
      "✓ Extracted 10 complaints from page 2\n",
      "Fetching page 3...\n",
      "Fetching page 3...\n",
      "✓ Extracted 10 complaints from page 3\n",
      "✓ Extracted 10 complaints from page 3\n",
      "Fetching page 4...\n",
      "Fetching page 4...\n",
      "✓ Extracted 10 complaints from page 4\n",
      "✓ Extracted 10 complaints from page 4\n",
      "Fetching page 5...\n",
      "Fetching page 5...\n",
      "✓ Extracted 10 complaints from page 5\n",
      "✓ Extracted 10 complaints from page 5\n",
      "Fetching page 6...\n",
      "Fetching page 6...\n",
      "✓ Extracted 10 complaints from page 6\n",
      "✓ Extracted 10 complaints from page 6\n",
      "Fetching page 7...\n",
      "Fetching page 7...\n",
      "✓ Extracted 10 complaints from page 7\n",
      "✓ Extracted 10 complaints from page 7\n",
      "Fetching page 8...\n",
      "Fetching page 8...\n",
      "✓ Extracted 10 complaints from page 8\n",
      "✓ Extracted 10 complaints from page 8\n",
      "Fetching page 9...\n",
      "Fetching page 9...\n",
      "✓ Extracted 10 complaints from page 9\n",
      "✓ Extracted 10 complaints from page 9\n",
      "Fetching page 10...\n",
      "Fetching page 10...\n",
      "✓ Extracted 10 complaints from page 10\n",
      "✓ Extracted 10 complaints from page 10\n",
      "Fetching page 11...\n",
      "Fetching page 11...\n",
      "✓ Extracted 10 complaints from page 11\n",
      "✓ Extracted 10 complaints from page 11\n",
      "Fetching page 12...\n",
      "Fetching page 12...\n",
      "✓ Extracted 10 complaints from page 12\n",
      "✓ Extracted 10 complaints from page 12\n",
      "Fetching page 13...\n",
      "Fetching page 13...\n",
      "✓ Extracted 10 complaints from page 13\n",
      "✓ Extracted 10 complaints from page 13\n",
      "Fetching page 14...\n",
      "Fetching page 14...\n",
      "✓ Extracted 10 complaints from page 14\n",
      "✓ Extracted 10 complaints from page 14\n",
      "Fetching page 15...\n",
      "Fetching page 15...\n",
      "✓ Extracted 10 complaints from page 15\n",
      "✓ Extracted 10 complaints from page 15\n",
      "Fetching page 16...\n",
      "Fetching page 16...\n",
      "✓ Extracted 10 complaints from page 16\n",
      "✓ Extracted 10 complaints from page 16\n",
      "Fetching page 17...\n",
      "Fetching page 17...\n",
      "✓ Extracted 10 complaints from page 17\n",
      "✓ Extracted 10 complaints from page 17\n",
      "Fetching page 18...\n",
      "Fetching page 18...\n",
      "✓ Extracted 10 complaints from page 18\n",
      "✓ Extracted 10 complaints from page 18\n",
      "Fetching page 19...\n",
      "Fetching page 19...\n",
      "✓ Extracted 10 complaints from page 19\n",
      "✓ Extracted 10 complaints from page 19\n",
      "Fetching page 20...\n",
      "Fetching page 20...\n",
      "✓ Extracted 10 complaints from page 20\n",
      "\n",
      "✓ Total complaints collected: 200\n",
      "✓ Extracted 10 complaints from page 20\n",
      "\n",
      "✓ Total complaints collected: 200\n",
      "Reclamações disponíveis: 200\n",
      "Reclamações disponíveis: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "complaint_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "complaint_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "349634d0-a5a2-4389-8446-f6808bb216e2",
       "rows": [
        [
         "0",
         "COMPLAINT_FNftCrSvmjTVSTIi",
         "Negativa de garantia para peça substituída anteriormente (Volante do motor) - Sprinter 417",
         "Aguardando resposta"
        ],
        [
         "1",
         "COMPLAINT_hMBfJpzQmQ46G4_k",
         "Caminhão com [NOME] de Óleo e [NOME] em Garantia",
         "Aguardando resposta"
        ],
        [
         "2",
         "COMPLAINT_LeSwbKMr-EZHSWpw",
         "[NOME] 2024/2025 com problemas na marcha e direção com 8.500 km",
         "Aguardando resposta"
        ],
        [
         "3",
         "COMPLAINT_A5atRAmWVxU9E32k",
         "Absurdo no preço do banco e durabilidade inferior ao de um Uno 2006",
         "Aguardando resposta"
        ],
        [
         "4",
         "COMPLAINT_E5euaQanLCg2t2et",
         "Solicitação de [NOME] e Revisão da Análise de Craquelamento em Assento de Mercedes GLB 200",
         "Aguardando resposta"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>complaint_title</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLAINT_FNftCrSvmjTVSTIi</td>\n",
       "      <td>Negativa de garantia para peça substituída ant...</td>\n",
       "      <td>Aguardando resposta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPLAINT_hMBfJpzQmQ46G4_k</td>\n",
       "      <td>Caminhão com [NOME] de Óleo e [NOME] em Garantia</td>\n",
       "      <td>Aguardando resposta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMPLAINT_LeSwbKMr-EZHSWpw</td>\n",
       "      <td>[NOME] 2024/2025 com problemas na marcha e dir...</td>\n",
       "      <td>Aguardando resposta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMPLAINT_A5atRAmWVxU9E32k</td>\n",
       "      <td>Absurdo no preço do banco e durabilidade infer...</td>\n",
       "      <td>Aguardando resposta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMPLAINT_E5euaQanLCg2t2et</td>\n",
       "      <td>Solicitação de [NOME] e Revisão da Análise de ...</td>\n",
       "      <td>Aguardando resposta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 complaint_id  \\\n",
       "0  COMPLAINT_FNftCrSvmjTVSTIi   \n",
       "1  COMPLAINT_hMBfJpzQmQ46G4_k   \n",
       "2  COMPLAINT_LeSwbKMr-EZHSWpw   \n",
       "3  COMPLAINT_A5atRAmWVxU9E32k   \n",
       "4  COMPLAINT_E5euaQanLCg2t2et   \n",
       "\n",
       "                                     complaint_title               status  \n",
       "0  Negativa de garantia para peça substituída ant...  Aguardando resposta  \n",
       "1   Caminhão com [NOME] de Óleo e [NOME] em Garantia  Aguardando resposta  \n",
       "2  [NOME] 2024/2025 com problemas na marcha e dir...  Aguardando resposta  \n",
       "3  Absurdo no preço do banco e durabilidade infer...  Aguardando resposta  \n",
       "4  Solicitação de [NOME] e Revisão da Análise de ...  Aguardando resposta  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scraper import ReclameAquiAPIExtractor, SELENIUM_AVAILABLE\n",
    "\n",
    "complaints_path = Path(config.COMPLAINTS_FILE)\n",
    "fallback_path = PROJECT_ROOT / \"input\" / \"complaints_raw.json\"\n",
    "\n",
    "# Extrair reclamações do ReclameAqui\n",
    "if SELENIUM_AVAILABLE:\n",
    "    extractor = ReclameAquiAPIExtractor(config.RECLAME_AQUI_URL, delay=1.5)\n",
    "    complaints = extractor.scrape_all_complaints(max_pages=20)\n",
    "else:\n",
    "    if fallback_path.exists():\n",
    "        print(\n",
    "            \"Selenium não disponível. Reutilizando base salva em input/complaints_raw.json.\"\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"Nem Selenium nem arquivo local disponível para carregar as reclamações.\"\n",
    "        )\n",
    "\n",
    "with open(complaints_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(complaints, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Reclamações disponíveis: {len(complaints)}\")\n",
    "pd.DataFrame(complaints)[[\"complaint_id\", \"complaint_title\", \"status\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a311e4",
   "metadata": {},
   "source": [
    "### Configuração de Agentes com YAML\n",
    "\n",
    "Para facilitar a manutenção e permitir ajustes rápidos sem alterar código, externalizamos as configurações dos agentes LLM em arquivos YAML.\n",
    "\n",
    "#### Estrutura de Diretórios\n",
    "```\n",
    "02. Classificador RA/\n",
    "├── agents/\n",
    "│   ├── theme_discovery.yaml        # Agente de descoberta de temas\n",
    "│   └── complaint_classifier.yaml   # Agente de classificação\n",
    "└── src/\n",
    "    ├── agent_loader.py             # Carrega configs YAML\n",
    "    ├── theme_discovery.py          # Usa theme_discovery.yaml\n",
    "    └── classifier.py               # Usa complaint_classifier.yaml\n",
    "```\n",
    "\n",
    "#### Exemplo de Arquivo YAML: `agents/theme_discovery.yaml`\n",
    "\n",
    "```model: \"gpt-4-turbo\"\n",
    "temperature:  0.3\n",
    "max_tokens: 2000\n",
    "\n",
    "system_prompt: |\n",
    "  You are an expert in analyzing customer complaints and identifying patterns.\n",
    "  Your task is to propose a taxonomy of categories that best represents the themes\n",
    "  present in a set of complaints.\n",
    "\n",
    "user_prompt_template: |\n",
    "  Based on the following complaints, propose between {min_categories} and {max_categories}\n",
    "  thematic categories that would best organize them.\n",
    "  \n",
    "  Complaints:\n",
    "  {complaints_sample}\n",
    "  \n",
    "  Return ONLY valid JSON with this exact structure:\n",
    "  {{\n",
    "    \"proposed_categories\": [\n",
    "      {{\n",
    "        \"category_name\": \"Category Name\",\n",
    "        \"category_description\": \"Detailed description\",\n",
    "        \"keywords\": [\"keyword1\", \"keyword2\"]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "```\n",
    "\n",
    "#### Como Usar no Código\n",
    "\n",
    "```python\n",
    "# src/agent_loader.py\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def load_agent_config(agent_name: str) -> dict:\n",
    "    config_path = Path(__file__).parent.parent / \"agents\" / f\"{agent_name}.yaml\"\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "# src/theme_discovery.py\n",
    "from agent_loader import load_agent_config\n",
    "\n",
    "class ThemeDiscovery:\n",
    "    def __init__(self, api_key: str):\n",
    "        # Carrega configuração do YAML\n",
    "        self.config = load_agent_config('theme_discovery')\n",
    "        self.model = self.config['model']\n",
    "        self.temperature = self.config['temperature']\n",
    "        self.system_prompt = self.config['system_prompt']\n",
    "        \n",
    "    def generate_taxonomy(self, complaints):\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.config['user_prompt_template'].format(\n",
    "                    min_categories=5,\n",
    "                    max_categories=15,\n",
    "                    complaints_sample=complaints\n",
    "                )}\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "```\n",
    "\n",
    "#### Vantagens desta Abordagem\n",
    "\n",
    "1. **Separação de Responsabilidades**: Lógica de código separada de configuração\n",
    "2. **Iteração Rápida**: Ajuste prompts sem tocar no código Python\n",
    "3. **Controle de Versão**: Fácil comparar mudanças nos prompts via Git\n",
    "4. **Experimentação**: Teste múltiplas versões de prompts facilmente\n",
    "5. **Manutenibilidade**: Prompts longos ficam mais legíveis em YAML\n",
    "\n",
    "#### Reload de Configs no Notebook\n",
    "\n",
    "Se você alterar um arquivo YAML durante a execução do notebook, force o reload:\n",
    "\n",
    "```python\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if 'agent_loader' in sys.modules:\n",
    "    importlib.reload(sys.modules['agent_loader'])\n",
    "if 'theme_discovery' in sys.modules:\n",
    "    importlib.reload(sys.modules['theme_discovery'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f441e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ agent_loader recarregado\n",
      "\n",
      "Verificando YAML atual:\n",
      "theme_discovery model: gpt-4-turbo\n"
     ]
    }
   ],
   "source": [
    "# Forçar reload dos módulos para pegar alterações no YAML\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Recarregar módulos se já estiverem em cache\n",
    "if \"agent_loader\" in sys.modules:\n",
    "    importlib.reload(sys.modules[\"agent_loader\"])\n",
    "    print(\"✓ agent_loader recarregado\")\n",
    "\n",
    "if \"theme_discovery\" in sys.modules:\n",
    "    importlib.reload(sys.modules[\"theme_discovery\"])\n",
    "    print(\"✓ theme_discovery recarregado\")\n",
    "\n",
    "if \"classifier\" in sys.modules:\n",
    "    importlib.reload(sys.modules[\"classifier\"])\n",
    "    print(\"✓ classifier recarregado\")\n",
    "\n",
    "print(\"\\nVerificando YAML atual:\")\n",
    "from agent_loader import load_agent_config\n",
    "\n",
    "print(f\"theme_discovery model: {load_agent_config('theme_discovery').get('model')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6eb02",
   "metadata": {},
   "source": [
    "#### 2. Geração automática de categorias com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ca67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias propostas: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category_description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2a436ed2-6955-4312-8342-b29173d3a00e",
       "rows": [
        [
         "0",
         "Warranty and Part Replacement Issues",
         "Customers express dissatisfaction due to denied warranty claims and issues with part replacements which they believe should be covered or have been delayed excessively."
        ],
        [
         "1",
         "Quality and Durability Concerns",
         "Customers report problems with the quality and durability of vehicle components, which do not meet their expectations for premium vehicles."
        ],
        [
         "2",
         "Service and Support Challenges",
         "Customers encounter poor service experiences including delayed repairs, lack of support, and unsatisfactory resolutions from dealerships."
        ],
        [
         "3",
         "Technology and Connectivity Issues",
         "Issues related to the functionality and user access to in-vehicle technology and connectivity features, such as remote functions and user profile settings."
        ],
        [
         "4",
         "Cost and Pricing Disputes",
         "Customers feel certain costs are unjustified, including charges for services and parts, or find pricing to be inconsistent and overly high."
        ],
        [
         "5",
         "Recall Management Issues",
         "Customers are dissatisfied with how recalls are handled, including denial of recall services and poor communication."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warranty and Part Replacement Issues</td>\n",
       "      <td>Customers express dissatisfaction due to denie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quality and Durability Concerns</td>\n",
       "      <td>Customers report problems with the quality and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service and Support Challenges</td>\n",
       "      <td>Customers encounter poor service experiences i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology and Connectivity Issues</td>\n",
       "      <td>Issues related to the functionality and user a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost and Pricing Disputes</td>\n",
       "      <td>Customers feel certain costs are unjustified, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall Management Issues</td>\n",
       "      <td>Customers are dissatisfied with how recalls ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category_name  \\\n",
       "0  Warranty and Part Replacement Issues   \n",
       "1       Quality and Durability Concerns   \n",
       "2        Service and Support Challenges   \n",
       "3    Technology and Connectivity Issues   \n",
       "4             Cost and Pricing Disputes   \n",
       "5              Recall Management Issues   \n",
       "\n",
       "                                category_description  \n",
       "0  Customers express dissatisfaction due to denie...  \n",
       "1  Customers report problems with the quality and...  \n",
       "2  Customers encounter poor service experiences i...  \n",
       "3  Issues related to the functionality and user a...  \n",
       "4  Customers feel certain costs are unjustified, ...  \n",
       "5  Customers are dissatisfied with how recalls ar...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uso da API - Fase 2 (Theme Discovery):\n",
      "{\n",
      "  \"total_tokens\": 18308,\n",
      "  \"input_tokens\": 17731,\n",
      "  \"output_tokens\": 577,\n",
      "  \"estimated_cost_usd\": 0.1946,\n",
      "  \"api_calls\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from theme_discovery import ThemeDiscovery\n",
    "\n",
    "if not config.OPENAI_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Defina OPENAI_API_KEY no arquivo .env antes de gerar a taxonomia.\"\n",
    "    )\n",
    "\n",
    "# Classe do Theme Discovery\n",
    "discovery = ThemeDiscovery(config.OPENAI_API_KEY, track_usage=True)\n",
    "\n",
    "# Verificando se iremos trackear utilização da API\n",
    "if discovery.tracker:\n",
    "    discovery.tracker.start_session(\n",
    "        \"Notebook - Fase 2 (Theme Discovery)\", discovery.model\n",
    "    )\n",
    "\n",
    "complaints = discovery.load_complaints(config.COMPLAINTS_FILE)\n",
    "sample = discovery.sample_complaints(complaints, config.SAMPLE_SIZE_FOR_DISCOVERY)\n",
    "taxonomy_payload = discovery.generate_taxonomy(sample)\n",
    "discovery.save_taxonomy(\n",
    "    taxonomy_payload, config.PROPOSED_TAXONOMY_FILE\n",
    ")  # Salvar taxonomia proposta\n",
    "\n",
    "print(f\"Categorias propostas: {len(taxonomy_payload['proposed_categories'])}\")\n",
    "taxonomy_df = pd.DataFrame(taxonomy_payload[\"proposed_categories\"])\n",
    "display(taxonomy_df[[\"category_name\", \"category_description\"]])\n",
    "\n",
    "if discovery.tracker:\n",
    "    session_data = discovery.tracker.end_session()\n",
    "    if session_data:\n",
    "        print(\"\\nUso da API - Fase 2 (Theme Discovery):\")\n",
    "        print(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"total_tokens\": session_data[\"total_tokens\"],\n",
    "                    \"input_tokens\": session_data[\"total_input_tokens\"],\n",
    "                    \"output_tokens\": session_data[\"total_output_tokens\"],\n",
    "                    \"estimated_cost_usd\": session_data[\"estimated_cost_usd\"],\n",
    "                    \"api_calls\": len(session_data[\"calls\"]),\n",
    "                },\n",
    "                indent=2,\n",
    "                ensure_ascii=False,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765deb2",
   "metadata": {},
   "source": [
    "#### 3. Classificação das reclamações com a taxonomia definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0c0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying complaints: 100%|██████████| 20/20 [03:11<00:00,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclamações classificadas nesta célula: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "percentage",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a845d221-b5de-47ad-b978-6b2a6de0af27",
       "rows": [
        [
         "0",
         "Quality and Durability Concerns",
         "78",
         "39.0"
        ],
        [
         "1",
         "Warranty and Part Replacement Issues",
         "54",
         "27.0"
        ],
        [
         "2",
         "Service and Support Challenges",
         "23",
         "11.5"
        ],
        [
         "3",
         "Technology and Connectivity Issues",
         "20",
         "10.0"
        ],
        [
         "4",
         "OTHER",
         "12",
         "6.0"
        ],
        [
         "5",
         "Recall Management Issues",
         "10",
         "5.0"
        ],
        [
         "6",
         "Cost and Pricing Disputes",
         "3",
         "1.5"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality and Durability Concerns</td>\n",
       "      <td>78</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Warranty and Part Replacement Issues</td>\n",
       "      <td>54</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service and Support Challenges</td>\n",
       "      <td>23</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology and Connectivity Issues</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall Management Issues</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cost and Pricing Disputes</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               category  count  percentage\n",
       "0       Quality and Durability Concerns     78        39.0\n",
       "1  Warranty and Part Replacement Issues     54        27.0\n",
       "2        Service and Support Challenges     23        11.5\n",
       "3    Technology and Connectivity Issues     20        10.0\n",
       "4                                 OTHER     12         6.0\n",
       "5              Recall Management Issues     10         5.0\n",
       "6             Cost and Pricing Disputes      3         1.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uso da API - Fase 3 (Classificação):\n",
      "{\n",
      "  \"total_tokens\": 30160,\n",
      "  \"input_tokens\": 22507,\n",
      "  \"output_tokens\": 7653,\n",
      "  \"estimated_cost_usd\": 0.008,\n",
      "  \"api_calls\": 20\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from classifier import ComplaintClassifier\n",
    "\n",
    "if not config.OPENAI_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Defina OPENAI_API_KEY no arquivo .env antes de classificar as reclamações.\"\n",
    "    )\n",
    "\n",
    "taxonomy_path = Path(config.CURATED_TAXONOMY_FILE)\n",
    "if not taxonomy_path.exists():\n",
    "    print(\"Taxonomia curada não encontrada. Usando proposta recém-gerada.\")\n",
    "    taxonomy_path = Path(config.PROPOSED_TAXONOMY_FILE)\n",
    "\n",
    "classifier = ComplaintClassifier(config.OPENAI_API_KEY, track_usage=True)\n",
    "if classifier.tracker:\n",
    "    classifier.tracker.start_session(\n",
    "        \"Notebook - Fase 3 (Classificação)\", classifier.model\n",
    "    )\n",
    "\n",
    "taxonomy = classifier.load_taxonomy(str(taxonomy_path))\n",
    "complaints = classifier.load_complaints(config.COMPLAINTS_FILE)\n",
    "results = classifier.classify_all(\n",
    "    complaints=complaints, taxonomy=taxonomy, use_batch=True\n",
    ")\n",
    "summary = classifier.generate_summary(results)\n",
    "\n",
    "output_payload = {\n",
    "    \"taxonomy_used\": taxonomy,\n",
    "    \"classification_results\": results,\n",
    "    \"summary\": summary,\n",
    "}\n",
    "with open(config.CLASSIFICATION_RESULTS_FILE, \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(output_payload, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Reclamações classificadas nesta célula: {len(results)}\")\n",
    "display(pd.DataFrame(summary[\"category_distribution\"]))\n",
    "\n",
    "if classifier.tracker:\n",
    "    session_data = classifier.tracker.end_session()\n",
    "    if session_data:\n",
    "        print(\"\\nUso da API - Fase 3 (Classificação):\")\n",
    "        print(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"total_tokens\": session_data[\"total_tokens\"],\n",
    "                    \"input_tokens\": session_data[\"total_input_tokens\"],\n",
    "                    \"output_tokens\": session_data[\"total_output_tokens\"],\n",
    "                    \"estimated_cost_usd\": session_data[\"estimated_cost_usd\"],\n",
    "                    \"api_calls\": len(session_data[\"calls\"]),\n",
    "                },\n",
    "                indent=2,\n",
    "                ensure_ascii=False,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23fd01",
   "metadata": {},
   "source": [
    "### Insights Adicionais e Análises Possíveis\n",
    "\n",
    "#### Análises Quantitativas\n",
    "- **Evolução temporal**: Identificar tendências de reclamações ao longo do tempo (sazonalidade, picos)\n",
    "- **Análise de sentimento**: Classificar reclamações por intensidade emocional (urgente, frustrado, neutro)\n",
    "- **Taxa de resolução**: Correlacionar categorias com status de resolução para identificar gargalos\n",
    "\n",
    "#### Análises Qualitativas\n",
    "- **Extração de palavras-chave**: Identificar termos mais frequentes por categoria usando TF-IDF ou embeddings\n",
    "- **Clustering automático**: Agrupar reclamações similares para descobrir subcategorias não mapeadas\n",
    "- **Análise de causa raiz**: Usar LLMs para identificar causas subjacentes comuns em cada categoria\n",
    "\n",
    "#### Análises Comparativas\n",
    "- **Benchmarking**: Comparar padrões de reclamações entre diferentes modelos de veículos ou concessionárias\n",
    "- **Análise competitiva**: Contrastar taxonomia e volumes com outras montadoras premium\n",
    "\n",
    "#### Automatização e Monitoramento\n",
    "- **Alertas inteligentes**: Detectar anomalias (ex: aumento súbito de reclamações em categoria específica)\n",
    "- **Dashboard em tempo real**: Visualizar distribuição de categorias e métricas de classificação\n",
    "- **Sistema de priorização**: Ranquear reclamações por urgência e impacto potencial usando scoring multi-critério"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
